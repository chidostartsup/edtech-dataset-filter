{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š FineWeb-Edu Subject Filter\n",
    "\n",
    "Filter FineWeb-Edu dataset by academic subject using vector embeddings.\n",
    "\n",
    "**Approach:**\n",
    "1. Define subject anchors (canonical descriptions)\n",
    "2. Embed anchors and documents with a strong embedding model\n",
    "3. Compute cosine similarity to assign subjects\n",
    "4. Export filtered subsets\n",
    "\n",
    "No classifier training needed â€” pure embedding similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install datasets sentence-transformers faiss-cpu pandas numpy tqdm huggingface_hub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Subject Anchors\n",
    "\n",
    "Each subject gets multiple anchor texts â€” canonical descriptions that capture what content in that subject looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_ANCHORS = {\n",
    "    \"mathematics\": [\n",
    "        \"Mathematics, algebra, calculus, geometry, and mathematical proofs\",\n",
    "        \"Solving equations, derivatives, integrals, and mathematical theorems\",\n",
    "        \"Linear algebra, matrices, vectors, and mathematical analysis\",\n",
    "        \"Probability theory, statistics, and mathematical modeling\",\n",
    "        \"Number theory, discrete mathematics, and combinatorics\"\n",
    "    ],\n",
    "    \"physics\": [\n",
    "        \"Physics, mechanics, thermodynamics, and electromagnetism\",\n",
    "        \"Quantum mechanics, relativity, and particle physics\",\n",
    "        \"Newton's laws, force, energy, momentum, and motion\",\n",
    "        \"Waves, optics, acoustics, and electromagnetic radiation\",\n",
    "        \"Astrophysics, cosmology, and gravitational physics\"\n",
    "    ],\n",
    "    \"chemistry\": [\n",
    "        \"Chemistry, chemical reactions, molecules, and compounds\",\n",
    "        \"Organic chemistry, inorganic chemistry, and biochemistry\",\n",
    "        \"Periodic table, elements, atoms, and chemical bonding\",\n",
    "        \"Stoichiometry, molarity, and chemical equilibrium\",\n",
    "        \"Acids, bases, pH, and electrochemistry\"\n",
    "    ],\n",
    "    \"biology\": [\n",
    "        \"Biology, cells, genetics, and evolution\",\n",
    "        \"DNA, RNA, proteins, and molecular biology\",\n",
    "        \"Ecology, ecosystems, biodiversity, and environmental science\",\n",
    "        \"Human anatomy, physiology, and organ systems\",\n",
    "        \"Microbiology, bacteria, viruses, and immunology\"\n",
    "    ],\n",
    "    \"computer_science\": [\n",
    "        \"Computer science, algorithms, data structures, and programming\",\n",
    "        \"Software engineering, databases, and system design\",\n",
    "        \"Machine learning, artificial intelligence, and neural networks\",\n",
    "        \"Operating systems, computer architecture, and networking\",\n",
    "        \"Cybersecurity, cryptography, and information security\"\n",
    "    ],\n",
    "    \"history\": [\n",
    "        \"History, historical events, civilizations, and historical figures\",\n",
    "        \"World War, ancient history, medieval history, and modern history\",\n",
    "        \"American history, European history, and Asian history\",\n",
    "        \"Political history, social movements, and revolutions\",\n",
    "        \"Archaeology, historical documents, and historiography\"\n",
    "    ],\n",
    "    \"literature\": [\n",
    "        \"Literature, novels, poetry, and literary analysis\",\n",
    "        \"Shakespeare, classic literature, and contemporary fiction\",\n",
    "        \"Literary criticism, narrative techniques, and symbolism\",\n",
    "        \"Drama, prose, verse, and creative writing\",\n",
    "        \"World literature, genres, and literary movements\"\n",
    "    ],\n",
    "    \"economics\": [\n",
    "        \"Economics, microeconomics, macroeconomics, and economic theory\",\n",
    "        \"Supply and demand, market equilibrium, and price theory\",\n",
    "        \"GDP, inflation, monetary policy, and fiscal policy\",\n",
    "        \"International trade, finance, and economic development\",\n",
    "        \"Behavioral economics, game theory, and econometrics\"\n",
    "    ],\n",
    "    \"law\": [\n",
    "        \"Law, legal systems, jurisprudence, and legislation\",\n",
    "        \"Constitutional law, criminal law, and civil law\",\n",
    "        \"Contracts, torts, property law, and legal procedures\",\n",
    "        \"International law, human rights, and legal ethics\",\n",
    "        \"Court cases, legal precedents, and judicial review\"\n",
    "    ],\n",
    "    \"medicine\": [\n",
    "        \"Medicine, medical diagnosis, treatment, and healthcare\",\n",
    "        \"Diseases, symptoms, pathology, and pharmacology\",\n",
    "        \"Clinical medicine, surgery, and medical procedures\",\n",
    "        \"Public health, epidemiology, and preventive medicine\",\n",
    "        \"Medical research, clinical trials, and evidence-based medicine\"\n",
    "    ],\n",
    "    \"philosophy\": [\n",
    "        \"Philosophy, ethics, metaphysics, and epistemology\",\n",
    "        \"Logic, reasoning, and philosophical arguments\",\n",
    "        \"Political philosophy, aesthetics, and philosophy of mind\",\n",
    "        \"Ancient philosophy, modern philosophy, and contemporary philosophy\",\n",
    "        \"Existentialism, phenomenology, and analytic philosophy\"\n",
    "    ],\n",
    "    \"psychology\": [\n",
    "        \"Psychology, cognitive psychology, and behavioral psychology\",\n",
    "        \"Mental health, psychological disorders, and therapy\",\n",
    "        \"Developmental psychology, social psychology, and personality\",\n",
    "        \"Neuroscience, brain function, and cognitive science\",\n",
    "        \"Psychological research, experiments, and psychological theories\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(SUBJECT_ANCHORS)} subjects\")\n",
    "for subject, anchors in SUBJECT_ANCHORS.items():\n",
    "    print(f\"  - {subject}: {len(anchors)} anchors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a strong, fast embedding model\n",
    "# Alternatives: \"BAAI/bge-large-en-v1.5\", \"thenlper/gte-large\", \"Snowflake/snowflake-arctic-embed-m\"\n",
    "MODEL_NAME = \"BAAI/bge-small-en-v1.5\"  # Small for testing, swap to bge-large for production\n",
    "\n",
    "print(f\"Loading embedding model: {MODEL_NAME}\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embed Subject Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_anchors(subject_anchors, model):\n",
    "    \"\"\"Embed all anchor texts and compute mean embedding per subject.\"\"\"\n",
    "    subject_embeddings = {}\n",
    "    \n",
    "    for subject, anchors in subject_anchors.items():\n",
    "        # Embed all anchors for this subject\n",
    "        embeddings = model.encode(anchors, normalize_embeddings=True)\n",
    "        # Take the mean as the subject centroid\n",
    "        subject_embeddings[subject] = np.mean(embeddings, axis=0)\n",
    "    \n",
    "    return subject_embeddings\n",
    "\n",
    "print(\"Embedding subject anchors...\")\n",
    "subject_embeddings = embed_anchors(SUBJECT_ANCHORS, model)\n",
    "\n",
    "# Stack into matrix for fast similarity computation\n",
    "subjects = list(subject_embeddings.keys())\n",
    "subject_matrix = np.stack([subject_embeddings[s] for s in subjects])\n",
    "print(f\"Subject embedding matrix shape: {subject_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load FineWeb-Edu Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample â€” adjust size based on your compute\n",
    "# For full dataset, use streaming=True and process in batches\n",
    "\n",
    "SAMPLE_SIZE = 10000  # Start small for testing\n",
    "\n",
    "print(f\"Loading FineWeb-Edu sample ({SAMPLE_SIZE} docs)...\")\n",
    "dataset = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb-edu\",\n",
    "    name=\"sample-10BT\",  # Use the 10B token sample, or \"default\" for full\n",
    "    split=f\"train[:{SAMPLE_SIZE}]\"\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(dataset)} documents\")\n",
    "print(f\"Columns: {dataset.column_names}\")\n",
    "print(f\"\\nSample document:\")\n",
    "print(dataset[0]['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classify Documents by Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_documents(texts, model, subject_matrix, subjects, batch_size=64, max_length=512):\n",
    "    \"\"\"\n",
    "    Classify documents by computing similarity to subject centroids.\n",
    "    \n",
    "    Returns:\n",
    "        labels: List of assigned subject labels\n",
    "        scores: List of similarity scores for assigned subject\n",
    "        all_scores: Matrix of all similarity scores (docs x subjects)\n",
    "    \"\"\"\n",
    "    all_scores = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Classifying\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Truncate long texts (embedding models have limits)\n",
    "        batch_texts = [t[:max_length * 4] for t in batch_texts]  # ~4 chars per token approx\n",
    "        \n",
    "        # Embed batch\n",
    "        batch_embeddings = model.encode(batch_texts, normalize_embeddings=True)\n",
    "        \n",
    "        # Compute cosine similarity to all subjects\n",
    "        # Since embeddings are normalized, dot product = cosine similarity\n",
    "        similarities = batch_embeddings @ subject_matrix.T\n",
    "        all_scores.append(similarities)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_scores = np.vstack(all_scores)\n",
    "    \n",
    "    # Get best subject for each document\n",
    "    best_indices = np.argmax(all_scores, axis=1)\n",
    "    labels = [subjects[i] for i in best_indices]\n",
    "    scores = [all_scores[i, best_indices[i]] for i in range(len(labels))]\n",
    "    \n",
    "    return labels, scores, all_scores\n",
    "\n",
    "# Run classification\n",
    "texts = dataset['text']\n",
    "labels, scores, all_scores = classify_documents(texts, model, subject_matrix, subjects)\n",
    "\n",
    "print(f\"\\nClassification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject distribution\n",
    "from collections import Counter\n",
    "\n",
    "distribution = Counter(labels)\n",
    "print(\"Subject Distribution:\")\n",
    "print(\"=\" * 40)\n",
    "for subject, count in distribution.most_common():\n",
    "    pct = count / len(labels) * 100\n",
    "    print(f\"{subject:20s}: {count:6d} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution\n",
    "print(f\"\\nConfidence Scores:\")\n",
    "print(f\"  Mean:   {np.mean(scores):.3f}\")\n",
    "print(f\"  Median: {np.median(scores):.3f}\")\n",
    "print(f\"  Min:    {np.min(scores):.3f}\")\n",
    "print(f\"  Max:    {np.max(scores):.3f}\")\n",
    "\n",
    "# How many are high confidence?\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "print(f\"\\nDocuments above confidence threshold:\")\n",
    "for thresh in thresholds:\n",
    "    count = sum(1 for s in scores if s >= thresh)\n",
    "    print(f\"  >= {thresh}: {count} ({count/len(scores)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents per subject\n",
    "print(\"\\nSample documents per subject:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for subject in subjects[:5]:  # First 5 subjects\n",
    "    print(f\"\\n[{subject.upper()}]\")\n",
    "    \n",
    "    # Get indices for this subject, sorted by confidence\n",
    "    subject_indices = [(i, scores[i]) for i, l in enumerate(labels) if l == subject]\n",
    "    subject_indices.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if subject_indices:\n",
    "        # Show top example\n",
    "        idx, score = subject_indices[0]\n",
    "        text = texts[idx][:300].replace('\\n', ' ')\n",
    "        print(f\"  Score: {score:.3f}\")\n",
    "        print(f\"  Text: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Filtered Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to dataset\n",
    "dataset_with_labels = dataset.add_column(\"subject\", labels)\n",
    "dataset_with_labels = dataset_with_labels.add_column(\"subject_score\", scores)\n",
    "\n",
    "print(f\"Dataset with labels: {dataset_with_labels}\")\n",
    "print(f\"New columns: {dataset_with_labels.column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by subject with confidence threshold\n",
    "CONFIDENCE_THRESHOLD = 0.4\n",
    "\n",
    "def export_subject(dataset, subject, threshold=0.4):\n",
    "    \"\"\"Filter dataset for a specific subject with confidence threshold.\"\"\"\n",
    "    filtered = dataset.filter(\n",
    "        lambda x: x['subject'] == subject and x['subject_score'] >= threshold\n",
    "    )\n",
    "    return filtered\n",
    "\n",
    "# Export each subject\n",
    "print(f\"Exporting subjects (threshold={CONFIDENCE_THRESHOLD}):\")\n",
    "for subject in subjects:\n",
    "    filtered = export_subject(dataset_with_labels, subject, CONFIDENCE_THRESHOLD)\n",
    "    print(f\"  {subject}: {len(filtered)} documents\")\n",
    "    \n",
    "    # Save to parquet\n",
    "    if len(filtered) > 0:\n",
    "        filtered.to_parquet(f\"fineweb_edu_{subject}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or save the full labeled dataset\n",
    "dataset_with_labels.to_parquet(\"fineweb_edu_labeled.parquet\")\n",
    "print(\"Saved full labeled dataset to fineweb_edu_labeled.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scale to Full Dataset (Streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For processing the full 1.3T token dataset, use streaming\n",
    "# This processes chunks without loading everything into memory\n",
    "\n",
    "def process_streaming(model, subject_matrix, subjects, batch_size=1000, max_docs=None):\n",
    "    \"\"\"\n",
    "    Process FineWeb-Edu in streaming mode for full-scale processing.\n",
    "    \"\"\"\n",
    "    from datasets import load_dataset\n",
    "    \n",
    "    # Load in streaming mode\n",
    "    stream = load_dataset(\n",
    "        \"HuggingFaceFW/fineweb-edu\",\n",
    "        name=\"default\",  # Full dataset\n",
    "        split=\"train\",\n",
    "        streaming=True\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    batch_texts = []\n",
    "    batch_ids = []\n",
    "    doc_count = 0\n",
    "    \n",
    "    for doc in tqdm(stream, desc=\"Processing\"):\n",
    "        batch_texts.append(doc['text'][:2000])  # Truncate\n",
    "        batch_ids.append(doc.get('id', doc_count))\n",
    "        \n",
    "        if len(batch_texts) >= batch_size:\n",
    "            # Process batch\n",
    "            embeddings = model.encode(batch_texts, normalize_embeddings=True)\n",
    "            similarities = embeddings @ subject_matrix.T\n",
    "            best_indices = np.argmax(similarities, axis=1)\n",
    "            \n",
    "            for i, (doc_id, idx) in enumerate(zip(batch_ids, best_indices)):\n",
    "                results.append({\n",
    "                    'id': doc_id,\n",
    "                    'subject': subjects[idx],\n",
    "                    'score': float(similarities[i, idx])\n",
    "                })\n",
    "            \n",
    "            batch_texts = []\n",
    "            batch_ids = []\n",
    "            doc_count += batch_size\n",
    "            \n",
    "            # Save periodically\n",
    "            if doc_count % 100000 == 0:\n",
    "                pd.DataFrame(results).to_parquet(f\"labels_checkpoint_{doc_count}.parquet\")\n",
    "        \n",
    "        if max_docs and doc_count >= max_docs:\n",
    "            break\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment to run on larger scale:\n",
    "# results = process_streaming(model, subject_matrix, subjects, max_docs=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Upload to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your filtered datasets to HuggingFace\n",
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "# Login (get token from https://huggingface.co/settings/tokens)\n",
    "# login(token=\"your_token_here\")\n",
    "\n",
    "def upload_to_hub(dataset, repo_name, private=False):\n",
    "    \"\"\"Upload dataset to HuggingFace Hub.\"\"\"\n",
    "    dataset.push_to_hub(\n",
    "        repo_name,\n",
    "        private=private\n",
    "    )\n",
    "    print(f\"Uploaded to https://huggingface.co/datasets/{repo_name}\")\n",
    "\n",
    "# Example:\n",
    "# upload_to_hub(math_dataset, \"your-username/fineweb-edu-math\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Bonus: Multi-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some documents might belong to multiple subjects\n",
    "# e.g., \"biophysics\" is both biology and physics\n",
    "\n",
    "def get_multi_labels(all_scores, subjects, threshold=0.35):\n",
    "    \"\"\"\n",
    "    Assign multiple labels to documents that score above threshold\n",
    "    for multiple subjects.\n",
    "    \"\"\"\n",
    "    multi_labels = []\n",
    "    \n",
    "    for doc_scores in all_scores:\n",
    "        doc_labels = [\n",
    "            subjects[i] \n",
    "            for i, score in enumerate(doc_scores) \n",
    "            if score >= threshold\n",
    "        ]\n",
    "        multi_labels.append(doc_labels if doc_labels else ['unknown'])\n",
    "    \n",
    "    return multi_labels\n",
    "\n",
    "multi_labels = get_multi_labels(all_scores, subjects, threshold=0.35)\n",
    "\n",
    "# How many docs have multiple labels?\n",
    "multi_count = sum(1 for labels in multi_labels if len(labels) > 1)\n",
    "print(f\"Documents with multiple subjects: {multi_count} ({multi_count/len(multi_labels)*100:.1f}%)\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nExamples of multi-label documents:\")\n",
    "for i, labels in enumerate(multi_labels[:100]):\n",
    "    if len(labels) > 1:\n",
    "        print(f\"  {labels}: {texts[i][:100]}...\")\n",
    "        if sum(1 for l in multi_labels[:i+1] if len(l) > 1) >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Scale up**: Run on full FineWeb-Edu using streaming mode\n",
    "2. **Validate**: Manually check samples from each subject for accuracy\n",
    "3. **Tune thresholds**: Adjust confidence thresholds per subject if needed\n",
    "4. **Better anchors**: Use actual textbook excerpts or Wikipedia intros as anchors\n",
    "5. **Publish**: Upload filtered subsets to HuggingFace Hub\n",
    "6. **Analyze**: Write up findings on subject distribution in FineWeb-Edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
